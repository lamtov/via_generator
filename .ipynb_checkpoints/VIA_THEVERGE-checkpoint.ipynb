{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.theverge.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "req = requests.get('https://www.theverge.com/forums', verify=False)\n",
    "req.encoding = 'utf-8'\n",
    "soup = BeautifulSoup(req.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link_forums():\n",
    "\n",
    "    req = requests.get('https://www.theverge.com/forums', verify=False)\n",
    "    req.encoding = 'utf-8'\n",
    "    soup = BeautifulSoup(req.text, 'lxml')\n",
    "    td_has_string=soup.find_all('a', class_='forum-icon-link')\n",
    "    #td_has_string[0]['href']\n",
    "\n",
    "    list_link_forums=[td['href'] for td in td_has_string]\n",
    "    # td_has_string[0].contents[0].contents[0].text.replace(\" \", \"\")\n",
    "\n",
    "    # list_name=[td.contents[0].contents[0].text.replace(\" \", \"\") for td in td_has_string]\n",
    "    # list_name\n",
    "    return list_link_forums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.theverge.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://www.theverge.com/2013/2/28/4039334/facebook-question-on-selling-your-info',\n",
       " 'https://www.theverge.com/2013/3/2/4057458/try-this-on-youtube',\n",
       " 'https://www.theverge.com/2013/3/2/4057668/if-you-use-time-warner-cable-and-youtube-vimeo-netflix-is-slow',\n",
       " 'https://www.theverge.com/2013/2/25/4029484/making-contact-cards-more-like-social-networks',\n",
       " 'https://www.theverge.com/2013/2/28/4040810/anyone-out-there-going-to-use-foundation-4',\n",
       " 'https://www.theverge.com/2013/2/27/4034814/michigan-universities-internet-down',\n",
       " 'https://www.theverge.com/2013/2/26/4033044/links-all-your-websites-in-one-place',\n",
       " 'https://www.theverge.com/2013/2/23/4021726/youtube-android-app-update-confirms-paid-channels-are-coming',\n",
       " 'https://www.theverge.com/2013/2/24/4024906/endless-pop-unders-with-chrome-on-windows-7',\n",
       " 'https://www.theverge.com/2013/2/24/4025478/academy-awards-second-screen',\n",
       " 'https://www.theverge.com/2013/2/22/4018256/massive-yahoo-spam-attack',\n",
       " 'https://www.theverge.com/2013/2/23/4022508/wireless-internet-really',\n",
       " 'https://www.theverge.com/2013/2/22/4019194/the-great-limitation-of-consumer-technology',\n",
       " 'https://www.theverge.com/2013/2/20/4011822/has-any-other-professional-photographer-seen-the-most-recent-portrait',\n",
       " 'https://www.theverge.com/2013/2/18/4001714/so-my-isp-just-redesigned-their-website-and-announced-new-plans',\n",
       " 'https://www.theverge.com/2013/2/18/4002698/how-often-do-you-check-your-email-and-other-workflow-woes',\n",
       " 'https://www.theverge.com/2013/2/15/3994146/facebook-timeline-redesigned-mockup-video',\n",
       " 'https://www.theverge.com/2013/2/19/4007646/you-may-not-know-just-how-much-cgi-goes-into-a-film',\n",
       " 'https://www.theverge.com/2013/2/18/4000428/klm-create-very-cool-social-media-map',\n",
       " 'https://www.theverge.com/2013/1/28/3925642/smartwatches-a-distraction',\n",
       " 'https://www.theverge.com/2013/2/7/3963160/what-should-a-fine-social-networking-app-have',\n",
       " 'https://www.theverge.com/2013/2/17/3999728/2013-nba-all-star-game-social-media-coverage',\n",
       " 'https://www.theverge.com/2013/2/3/3948466/uploading-copyrighted-material-in-youtube-in-private',\n",
       " 'https://www.theverge.com/2013/2/16/3996208/for-the-web-designers-out-there-where-are-the-best-responsive-design',\n",
       " 'https://www.theverge.com/2013/2/6/3961522/with-facebook-putting-off-mobile-will-or-can-an-underdog-emerge']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_tr(tag):\n",
    "    return tag.name=='tr' and (len(tag.contents)>0 and  tag.contents[0].name=='td' or tag.contents[1].name=='td'   )\n",
    "\n",
    "req = requests.get('https://www.theverge.com/forums/web-and-social/20', verify=False)\n",
    "req.encoding = 'utf-8'\n",
    "soup = BeautifulSoup(req.text, 'lxml')\n",
    "tr_has_string=soup.find_all(find_tr)\n",
    "\n",
    "list_posts=[]\n",
    "for tr in tr_has_string:\n",
    "    for td in  tr.contents:\n",
    "        if td.name=='td' and  len(td.contents)>0 and  (td.contents[0].name=='a' or td.contents[1].name=='a' ) :\n",
    "            if td.contents[0].name=='a' :\n",
    "                list_posts.append(td.contents[0]['href'])\n",
    "            else :\n",
    "                list_posts.append(td.contents[1]['href'])\n",
    "            break\n",
    "# tr_has_string[0].contents[1].contents\n",
    "list_posts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_list_post(link):\n",
    "    def find_tr(tag):\n",
    "        return tag.name=='tr' and (len(tag.contents)>0 and  tag.contents[0].name=='td' or tag.contents[1].name=='td'   )\n",
    "\n",
    "    req = requests.get(link, verify=False)\n",
    "    req.encoding = 'utf-8'\n",
    "    soup = BeautifulSoup(req.text, 'lxml')\n",
    "    tr_has_string=soup.find_all(find_tr)\n",
    "\n",
    "    list_posts=[]\n",
    "    for tr in tr_has_string:\n",
    "        for td in  tr.contents:\n",
    "            if td.name=='td' and  len(td.contents)>0 and  (td.contents[0].name=='a' or td.contents[1].name=='a' ) :\n",
    "                if td.contents[0].name=='a' :\n",
    "                    list_posts.append(td.contents[0]['href'])\n",
    "                else :\n",
    "                    list_posts.append(td.contents[1]['href'])\n",
    "                break\n",
    "    return list_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link_post(link_forum):\n",
    "    def find_tr(tag):\n",
    "        return tag.name=='tr' and (len(tag.contents)>0 and  tag.contents[0].name=='td'  and tag.contents[0].contents[0].name=='a'  )\n",
    "    num_post=1\n",
    "    page=1\n",
    "    list_link_forums=[]\n",
    "    while num_post!=0:\n",
    "        \n",
    "        link= link_forum+'/'+str(page)\n",
    "        \n",
    "        list_post=find_list_post(link)\n",
    "        num_post=len(list_post)\n",
    "        page=page+1\n",
    "        list_link_forums=list_link_forums+list_post\n",
    "        \n",
    "    return list_link_forums\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36\n",
      "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36\n"
     ]
    }
   ],
   "source": [
    "from test_chrome import Bot\n",
    "link_spam = \"https://scholar.google.com/\"\n",
    "proxy = '0.0.0.0:0'\n",
    "\n",
    "t = Bot(proxy, link_spam)\n",
    "t.spam()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.theverge.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['kirill_kuzyk',\n",
       " 'epinephrine2',\n",
       " 'aliatwa',\n",
       " 'Fake_ID',\n",
       " 'web0rama',\n",
       " 'NescolKellie',\n",
       " 'Chris Burgess 666',\n",
       " 'HenDrake',\n",
       " 'Richard Stafford',\n",
       " 'SnoopZ',\n",
       " 'wingzero0',\n",
       " 'alecogrady',\n",
       " 'Jessica Thomas3',\n",
       " 'wingzero0',\n",
       " 'MarcoLorenzo',\n",
       " 'Marta Go',\n",
       " 'Buggy3D',\n",
       " 'mrmelice',\n",
       " 'sonnyke',\n",
       " 'cy.starkman',\n",
       " 'holyblack',\n",
       " 'Cottonheadedninnymuggin',\n",
       " 'macboer',\n",
       " 'David Almaguer',\n",
       " 'marquon battle']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_tr(tag):\n",
    "    return tag.name=='tr' and (len(tag.contents)>0 and  tag.contents[0].name=='td' or tag.contents[1].name=='td'   )\n",
    "\n",
    "req = requests.get('https://www.theverge.com/forums/apps-software', verify=False)\n",
    "req.encoding = 'utf-8'\n",
    "soup = BeautifulSoup(req.text, 'lxml')\n",
    "tr_has_string=soup.find_all(find_tr)\n",
    "\n",
    "list_authors=set()\n",
    "for tr in tr_has_string:\n",
    "    if len(tr.contents)>1:\n",
    "        for td in  tr.contents[2:]:\n",
    "            if td.name=='td' and  len(td.contents)>0 and  (td.contents[0].name=='a' or td.contents[1].name=='a' ) :\n",
    "                if td.contents[0].name=='a' :\n",
    "                    list_authors.add(td.contents[0].text)\n",
    "                else :\n",
    "                    list_authors.add(td.contents[1].text)\n",
    "                break\n",
    "list_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link_forums():\n",
    "\n",
    "    req = requests.get('https://www.etsy.com/search/shops?ref=pagination&page=1241', verify=False)\n",
    "    req.encoding = 'utf-8'\n",
    "    soup = BeautifulSoup(req.text, 'lxml')\n",
    "    td_has_string=soup.find_all('a', class_='wt-text-title-01 wt-text-truncate')\n",
    "    #td_has_string[0]['href']\n",
    "\n",
    "    list_link_forums=[td['href'] for td in td_has_string]\n",
    "    # td_has_string[0].contents[0].contents[0].text.replace(\" \", \"\")\n",
    "\n",
    "    # list_name=[td.contents[0].contents[0].text.replace(\" \", \"\") for td in td_has_string]\n",
    "    # list_name\n",
    "    return list_link_forums"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
